{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.calibration import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text_with_stop_words_removal</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1807053896587919743</td>\n",
       "      <td>We should consider dismantling provincial stru...</td>\n",
       "      <td>consid dismantl provinci structur empow local ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1807031275989114981</td>\n",
       "      <td>Those joining in insurance online will be requ...</td>\n",
       "      <td>join insur onlin requir provid nation ident ca...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1807030978554269711</td>\n",
       "      <td>Minister Aryal also requested the provincial a...</td>\n",
       "      <td>minist aryal also request provinci local gover...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1807029744837300466</td>\n",
       "      <td>\\xf0\\x9f\\x8c\\xbe Happy National Paddy Day (Aas...</td>\n",
       "      <td>xf0x9fx8cxbe happi nation paddi day aasar 15 x...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1806998724926755034</td>\n",
       "      <td>Climate action plans and targets set by the Ne...</td>\n",
       "      <td>climat action plan target set nepal govern gui...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1807053896587919743  We should consider dismantling provincial stru...   \n",
       "1  1807031275989114981  Those joining in insurance online will be requ...   \n",
       "2  1807030978554269711  Minister Aryal also requested the provincial a...   \n",
       "3  1807029744837300466  \\xf0\\x9f\\x8c\\xbe Happy National Paddy Day (Aas...   \n",
       "4  1806998724926755034  Climate action plans and targets set by the Ne...   \n",
       "\n",
       "                cleaned_text_with_stop_words_removal     label  \n",
       "0  consid dismantl provinci structur empow local ...   neutral  \n",
       "1  join insur onlin requir provid nation ident ca...  positive  \n",
       "2  minist aryal also request provinci local gover...  positive  \n",
       "3  xf0x9fx8cxbe happi nation paddi day aasar 15 x...  positive  \n",
       "4  climat action plan target set nepal govern gui...  positive  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df = pd.read_csv('../data/labeled.csv')\n",
    "labeled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with null values in 'cleaned_text_with_stop_words_removal':\n",
      "                       id                                               text  \\\n",
      "7913  1149606322318401536  @SudeepS1402 @rsansar @katesictibet @LokAawaaz...   \n",
      "\n",
      "     cleaned_text_with_stop_words_removal    label  \n",
      "7913                                  NaN  neutral  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text_with_stop_words_removal</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, text, cleaned_text_with_stop_words_removal, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df.isnull().sum()\n",
    "null_rows = labeled_df[labeled_df['cleaned_text_with_stop_words_removal'].isnull()]\n",
    "print(\"Rows with null values in 'cleaned_text_with_stop_words_removal':\")\n",
    "print(null_rows)\n",
    "labeled_df.dropna(subset=['cleaned_text_with_stop_words_removal'], inplace=True)\n",
    "duplicates_text = labeled_df.duplicated(subset=['cleaned_text_with_stop_words_removal'])\n",
    "labeled_df[duplicates_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSvc(X_train, X_test, y_train, y_test):\n",
    "    # Train SVM model\n",
    "    svm_model = SVC(C=10, class_weight='balanced')\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate SVM model\n",
    "    svm_predictions = svm_model.predict(X_test)\n",
    "    print(\"SVM Model Performance:\")\n",
    "    print(classification_report(y_test, svm_predictions))\n",
    "\n",
    "def trainNaive(X_train, X_test, y_train, y_test):\n",
    "    # Train Naive Bayes model\n",
    "    nb_model = MultinomialNB()\n",
    "    nb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate Naive Bayes model\n",
    "    nb_predictions = nb_model.predict(X_test)\n",
    "    print(\"Naive Bayes Model Performance:\")\n",
    "    print(classification_report(y_test, nb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "\n",
    "\n",
    "def Vectorize(text):\n",
    "\n",
    "    tfidf = TfidfVectorizer(max_features=5000,ngram_range=(1,1))\n",
    "\n",
    "    # Fit and transform the labeled data\n",
    "    return tfidf.fit_transform(text)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countpositive = 0\n",
    "# countnegative=0\n",
    "# countneutral=0\n",
    "# for data in labeled_df['label']:\n",
    "#     # print(data)\n",
    "#     if data == 2:\n",
    "#         countpositive = countpositive +1\n",
    "#     elif data == 0:\n",
    "#         countnegative = countnegative +1\n",
    "#     else:\n",
    "#         countneutral = countneutral +1\n",
    "\n",
    "\n",
    "# print(countpositive,countnegative,countneutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       653\n",
      "           1       0.69      0.54      0.60       324\n",
      "           2       0.74      0.80      0.77       711\n",
      "\n",
      "    accuracy                           0.74      1688\n",
      "   macro avg       0.73      0.70      0.71      1688\n",
      "weighted avg       0.73      0.74      0.73      1688\n",
      "\n",
      "Naive Bayes Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.72       653\n",
      "           1       0.87      0.10      0.19       324\n",
      "           2       0.62      0.85      0.72       711\n",
      "\n",
      "    accuracy                           0.66      1688\n",
      "   macro avg       0.73      0.56      0.54      1688\n",
      "weighted avg       0.70      0.66      0.61      1688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_labeled = Vectorize(labeled_df['cleaned_text_with_stop_words_removal'])\n",
    "label_encoder = LabelEncoder()\n",
    "y_labeled = label_encoder.fit_transform(labeled_df['label'])\n",
    "\n",
    "\n",
    "# Split the labeled data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_labeled, y_labeled, test_size=0.2, stratify= y_labeled,random_state=42)\n",
    "# print(\"X_train:\", X_train)\n",
    "# print(\"X_test:\", X_test)\n",
    "# print(\"y_train:\", y_train)\n",
    "# print(\"y_test:\", y_test)\n",
    "\n",
    "\n",
    "trainSvc(X_train, X_test, y_train, y_test)\n",
    "trainNaive(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envsentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
